{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca24bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Split data into train, validation sets\n",
    "splitfolders.ratio('ImageDataset', output='output', seed=7557, ratio=(0.8, 0.2))\n",
    "\n",
    "# Define data directories\n",
    "train_dir = 'output/train'\n",
    "val_dir = 'output/val'\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "\n",
    "# Creating the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy',min_delta=0.01, patience=5, verbose=1)\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=30, verbose=2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "score = model.evaluate(val_generator,verbose=0)\n",
    "\n",
    "# Print the test accuracy\n",
    "test_accuracy = score[1]\n",
    "test_loss = score[0]\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Test loss: {test_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d812ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store accuracies and losses\n",
    "acc = []\n",
    "loss = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    seed = random.randint(1000, 9999)\n",
    "    splitfolders.ratio('data', output='output', seed=seed, ratio=(0.8, 0.2))\n",
    "\n",
    "    # Define data directories\n",
    "    train_dir = 'output/train'\n",
    "    val_dir = 'output/val'\n",
    "\n",
    "    # Create data generators\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,width_shift_range=0.1,height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,horizontal_flip=True)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "    val_generator = val_datagen.flow_from_directory(val_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "\n",
    "       # Create a simple CNN model\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')  \n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_generator, validation_data=val_generator, epochs=50, verbose=0,callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    score = model.evaluate(val_generator, verbose=2)\n",
    "\n",
    "    # Save test accuracy and loss\n",
    "    acc.append(score[1])\n",
    "    loss.append(score[0])\n",
    "\n",
    "# Calculate the average test accuracy and loss\n",
    "max_acc = np.max(acc)\n",
    "max_loss = np.max(loss)\n",
    "min_acc = np.min(acc)\n",
    "min_loss = np.min(loss)\n",
    "\n",
    "# Print the average test accuracy and loss\n",
    "print(f\"max accuracy: {max_acc:.2f}\")\n",
    "print(f\"max loss: {max_loss:.2f}\")\n",
    "print(f\"min accuracy: {min_acc:.2f}\")\n",
    "print(f\"min loss: {min_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acc3df",
   "metadata": {},
   "source": [
    "# V5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store accuracies and losses\n",
    "acc = []\n",
    "loss = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    seed = random.randint(1000, 9999)\n",
    "    splitfolders.ratio('data', output='output', seed=seed, ratio=(0.8, 0.2))\n",
    "\n",
    "    # Define data directories\n",
    "    train_dir = 'output/train'\n",
    "    val_dir = 'output/val'\n",
    "\n",
    "    # Create data generators\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "    val_generator = val_datagen.flow_from_directory(val_dir, target_size=(64, 64), batch_size=32, class_mode='categorical')\n",
    "\n",
    "       # Create a simple CNN model\n",
    "    # Create a simple CNN model\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')  # Adjust output units based on your shape classes\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_generator, validation_data=val_generator, epochs=30, verbose=0)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    score = model.evaluate(val_generator, verbose=2)\n",
    "\n",
    "    # Save test accuracy and loss\n",
    "    acc.append(score[1])\n",
    "    loss.append(score[0])\n",
    "\n",
    "# Calculate the average test accuracy and loss\n",
    "max_acc = np.max(acc)\n",
    "max_loss = np.max(loss)\n",
    "min_acc = np.min(acc)\n",
    "min_loss = np.min(loss)\n",
    "\n",
    "# Print the average test accuracy and loss\n",
    "print(f\"max accuracy: {max_acc:.2f}\")\n",
    "print(f\"max loss: {max_loss:.2f}\")\n",
    "print(f\"min accuracy: {min_acc:.2f}\")\n",
    "print(f\"min loss: {min_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b4c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8722c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
